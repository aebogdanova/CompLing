{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371970ff",
   "metadata": {},
   "source": [
    "# Домашнее задание № 3. Исправление опечаток"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35cf8bd",
   "metadata": {},
   "source": [
    "## 1. Доп. ранжирование по вероятности (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6be25c",
   "metadata": {},
   "source": [
    "Дополните get_closest_hybrid_match в семинаре так, чтобы из кандадатов с одинаковым расстоянием редактирования выбиралось наиболее вероятное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf38679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "from collections import Counter, defaultdict\n",
    "import textdistance\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dda7da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#открываем корпус и сохраняем слова в словарь частот\n",
    "corpus = open('wiki_data.txt', encoding='utf8').read()\n",
    "vocab = Counter(re.findall('\\w+', corpus.lower()))\n",
    "#сохраняем объем корпуса\n",
    "N = sum(vocab.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed3ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохраняем все слова из vocab в нумерованный словарь\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "#векторизуем слова из корпуса, признаками будут н-граммы символов от 1 до 3\n",
    "vec = CountVectorizer(analyzer='char', ngram_range=(1,3), max_features=1000)\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e8814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция с семинара для подсчета вероятностей\n",
    "def P(word, N=N):\n",
    "    return vocab[word] / N\n",
    "\n",
    "#функция с семинара для нахождения близких слов (по расстоянию редактирования)\n",
    "def get_closest_match_with_metric(text, lookup, topn=20, metric=textdistance.levenshtein):\n",
    "    similarities = Counter()\n",
    "    for word in lookup:\n",
    "        similarities[word] = metric.normalized_similarity(text, word) \n",
    "    return similarities.most_common(topn)\n",
    "\n",
    "#функция с семинара для нахождения близких слов (по косинусному расстоянию)\n",
    "def get_closest_match_vec(text, X, vec, topn=20):\n",
    "    v = vec.transform([text])\n",
    "    similarities = cosine_distances(v, X)[0]\n",
    "    topn = similarities.argsort()[:topn] \n",
    "    return [(id2word[top], similarities[top]) for top in topn]\n",
    "\n",
    "#функция с семинара для нахождения близких слов (сначала по косинусному расстоянию, затем по расстоянию редактирования)\n",
    "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "\n",
    "    #мой код для нахождения наиболее вероятных слов для кандидатов с одинаковым расстоянием редактирования\n",
    "    closest_reverse = defaultdict(list)\n",
    "    for candidate in closest:\n",
    "        closest_reverse[candidate[1]].append(candidate[0])\n",
    "    closest_reverse = {key: max([i for i in value], key=P) for key, value in closest_reverse.items()}\n",
    "    closest = Counter({value: key for key, value in closest_reverse.items()})\n",
    "\n",
    "    return closest.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c163efe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('солнце', 0.8333333333333334), ('соне', 0.8)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_hybrid_match('сонце', X, vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a35835",
   "metadata": {},
   "source": [
    "Посмотрим на метрики для нового алгоритма:\n",
    "1) Процент правильных слов;  \n",
    "2) Процент исправленных ошибок;\n",
    "3) Процент ошибочно исправленных правильных слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3533f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#загружаем датасеты для тестирования алгоритма\n",
    "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('correct_sents.txt', encoding='utf8').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa9ec490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#необходимые для подсчета метрик функции с семинара\n",
    "def align_words(sent_1, sent_2):\n",
    "    tokens_1 = sent_1.lower().split()\n",
    "    tokens_2 = sent_2.lower().split()\n",
    "    \n",
    "    tokens_1 = [token.strip(punctuation) for token in tokens_1]\n",
    "    tokens_2 = [token.strip(punctuation) for token in tokens_2]\n",
    "    \n",
    "    tokens_1 = [token for token in tokens_1 if token]\n",
    "    tokens_2 = [token for token in tokens_2 if token]\n",
    "    \n",
    "    assert len(tokens_1) == len(tokens_2)\n",
    "    \n",
    "    return list(zip(tokens_1, tokens_2))\n",
    "\n",
    "def predict_mistaken(word, vocab):\n",
    "    return 0 if word in vocab else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a994600b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0.8556278139069535\n",
      "0.48835403726708076\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "#код с семинара для подсчета метрик\n",
    "mistakes = []\n",
    "total_mistaken = 0\n",
    "mistaken_fixed = 0\n",
    "\n",
    "total_correct = 0\n",
    "correct_broken = 0\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "cashed = {}\n",
    "for i in range(len(true)):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "        if predict_mistaken(pair[1], vocab):\n",
    "            pred = cashed.get(pair[1], get_closest_hybrid_match(pair[1], X, vec)[0][0])\n",
    "            cashed[pair[1]] = pred\n",
    "        else:\n",
    "            pred = pair[1]\n",
    "        \n",
    "            \n",
    "        if pred == pair[0]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mistakes.append((pair[0], pair[1], pred))\n",
    "        total += 1\n",
    "            \n",
    "        if pair[0] == pair[1]:\n",
    "            total_correct += 1\n",
    "            if pair[0] != pred:\n",
    "                correct_broken += 1\n",
    "        else:\n",
    "            total_mistaken += 1\n",
    "            if pair[0] == pred:\n",
    "                mistaken_fixed += 1\n",
    "    \n",
    "    if not i % 100:\n",
    "        print(i)\n",
    "\n",
    "print(correct/total)\n",
    "print(mistaken_fixed/total_mistaken)\n",
    "print(correct_broken/total_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04253825",
   "metadata": {},
   "source": [
    "Процент исправленных ошибок немного увеличился по сравнению с исходным get_closest_hybrid_match (без учета вероятностей), однако наш алгоритм по метрикам все еще хуже, чем алгоритм Норвига, поэтому можно сказать, что учет вероятностей большого улучшения не дал.\n",
    "\n",
    "Метрики для get_closest_hybrid_match с семинара:<br>\n",
    "0.8527263631815908<br>\n",
    "0.4658385093167702<br>\n",
    "0.09004249454461927<br>\n",
    "\n",
    "Метрики для алгоритма Норвига с семинара:<br>\n",
    "0.8708354177088544<br>\n",
    "0.5116459627329193<br>\n",
    "0.07603077983231882<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf9985",
   "metadata": {},
   "source": [
    "## 2.  Symspell (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392cc23",
   "metadata": {},
   "source": [
    "Реализуйте алгоритм Symspell. Он похож на алгоритм Норвига, но проще и быстрее. Там к словам применяется только одна операция - удаление символа. Описание алгоритма по шагам:\n",
    "\n",
    "1) Составляется словарь правильных слов  \n",
    "2) На основе словаря правильных слов составляется словарь удалений - для каждого правильного слова создаются все варианты удалений и создается словарь, где ключ - слово с удалением, а значение - правильное слово   \n",
    "3) Для выбора исправления для слова с опечаткой генерируются все варианты удаления, из них выбираются те, что есть в словаре удалений, построенного на шаге 2. Слово с опечаткой заменяется на правильное слово, соответствующее варианту удаления  \n",
    "4) Если в словаре удалений есть несколько вариантов, то выбирается удаление, которому соответствует наиболее вероятное правильное слово  \n",
    "\n",
    "\n",
    "Оцените качество полученного алгоритма теми же тремя метриками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96c9fae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368802\n"
     ]
    }
   ],
   "source": [
    "#1. Словарь правильных слов vocab получен еще в первом задании, он состоит из 368802 слов\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22291913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Составляем словарь удалений vocab_deletes\n",
    "vocab_deletes = defaultdict(list)\n",
    "for word in vocab:\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]   \n",
    "    deletes = [L + R[1:] for L, R in splits if R]\n",
    "    for delete in deletes:\n",
    "        vocab_deletes[delete].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93bae552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Составляем функцию для исправления слова\n",
    "def correct_word(word):\n",
    "\n",
    "    #составляем для слова с опечаткой все варианты удаления\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes = [L + R[1:] for L, R in splits if R]\n",
    "    #добавляем в список само слово с опечаткой\n",
    "    deletes.append(word)\n",
    "    #выбираем среди этих вариантов те, которые встречаются в словаре удалений, сохраняем в список соответствующие им наиболее вероятные слова\n",
    "    candidates = []\n",
    "    for d in deletes:\n",
    "        if d in vocab_deletes:\n",
    "            candidates.append(max(vocab_deletes[d], key=P))\n",
    "    #из правильных слов выбираем то, у которого наибольшая вероятность\n",
    "    if candidates:\n",
    "        return max(candidates, key=P)\n",
    "    #если в словаре удалений нет подходящих вариантов исправлений, возвращаем само слово с опечаткой\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c0ff3",
   "metadata": {},
   "source": [
    "Теперь посмотрим на метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b894e3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43141570785392697\n",
      "0.32142857142857145\n",
      "0.5523142299299414\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_mistaken = 0\n",
    "mistaken_fixed = 0\n",
    "\n",
    "total_correct = 0\n",
    "correct_broken = 0\n",
    "\n",
    "cashed = {}\n",
    "for i in range(len(true)):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "\n",
    "        predicted = cashed.get(pair[1], correct_word(pair[1]))\n",
    "        cashed[pair[1]] = predicted\n",
    "        \n",
    "        if predicted == pair[0]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "        if pair[0] == pair[1]:\n",
    "            total_correct += 1\n",
    "            if pair[0] !=  predicted:\n",
    "                correct_broken += 1\n",
    "        else:\n",
    "            total_mistaken += 1\n",
    "            if pair[0] == predicted:\n",
    "                mistaken_fixed += 1\n",
    "\n",
    "print(correct/total)\n",
    "print(mistaken_fixed/total_mistaken)\n",
    "print(correct_broken/total_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0605f15d",
   "metadata": {},
   "source": [
    "Метрики значительно хуже, чем у алгоритма Норвига. Это может быть связано с тем, что у реализованного Symspell расстояние удаления - всего 1 символ (тем не менее, при удалении 1 и 2 символов будет появляться слишком много кандидатов, среди которых почти наверняка будут высоко вероятные, это нужно будет учитывать)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b292d96d",
   "metadata": {},
   "source": [
    "## *3. Настройка гиперпараметров. (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4b28f",
   "metadata": {},
   "source": [
    "У метода из первого заданий много гиперпараметров (те которые нужно подбирать самостоятельно). Это параметры векторайзера, topn, метрика редактирования. Поэкспериментируйте с ними. \n",
    "\n",
    "Проведите как минимум 10 экспериментов с разными параметрами. Для каждого эксперимента укажите мотивацию (например, \"слишком маленький topn в get_closest_match_vec приводит к тому, что некоторые хорошие варианты не доходят до get_closest_match_with_metric, попробуем его увеличить\")\n",
    "\n",
    "Старайтесь получить улучшение, но если улучшить не получится, то это не страшно. Главное, чтобы эксперименты были осмысленными, а не рандомными. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da2b0b",
   "metadata": {},
   "source": [
    "Для начала обернем код для подсчета метрик в функцию, чтобы было удобнее их считать при проведении экспериментов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f77c4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функции для подсчета метрик\n",
    "def predict_mistaken(word, vocab):\n",
    "    return 0 if word in vocab else 1\n",
    "\n",
    "def metrics(true=true, bad=bad):\n",
    "    \n",
    "    mistakes = []\n",
    "    total_mistaken = 0\n",
    "    mistaken_fixed = 0\n",
    "\n",
    "    total_correct = 0\n",
    "    correct_broken = 0\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    cashed = {}\n",
    "    for i in range(len(true)):\n",
    "        word_pairs = align_words(true[i], bad[i])\n",
    "        for pair in word_pairs:\n",
    "            if predict_mistaken(pair[1], vocab):\n",
    "                pred = cashed.get(pair[1], get_closest_hybrid_match(pair[1], X, vec)[0][0])\n",
    "                cashed[pair[1]] = pred\n",
    "            else:\n",
    "                pred = pair[1]\n",
    "                \n",
    "            if pred == pair[0]:\n",
    "                correct += 1\n",
    "            else:\n",
    "                mistakes.append((pair[0], pair[1], pred))\n",
    "            total += 1\n",
    "                \n",
    "            if pair[0] == pair[1]:\n",
    "                total_correct += 1\n",
    "                if pair[0] != pred:\n",
    "                    correct_broken += 1\n",
    "            else:\n",
    "                total_mistaken += 1\n",
    "                if pair[0] == pred:\n",
    "                    mistaken_fixed += 1\n",
    "\n",
    "        if not i % 100:\n",
    "            print(i)\n",
    "\n",
    "    print(correct/total)\n",
    "    print(mistaken_fixed/total_mistaken)\n",
    "    print(correct_broken/total_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a52ecf",
   "metadata": {},
   "source": [
    "1) Попробуем поэкспериментировать с метрикой редактирования. Для начала попробуем расстояние Левенштейна (в первом задании мы считали расстояние Дамерау-Левенштейна, которое учитывает не только операции вставки, удаления и замены символов, но и перестановки, однако хочется проверить, наколько сильно будут отличаться результаты, если перестановка учитываться не будет)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d41b92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "    closest_reverse = defaultdict(list)\n",
    "    for candidate in closest:\n",
    "        closest_reverse[candidate[1]].append(candidate[0])\n",
    "    closest_reverse = {key: max([i for i in value], key=P) for key, value in closest_reverse.items()}\n",
    "    closest = Counter({value: key for key, value in closest_reverse.items()})\n",
    "    return closest.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84a73306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0.854327163581791\n",
      "0.4782608695652174\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a7396b",
   "metadata": {},
   "source": [
    "2) Метрики все-таки чуть-чуть похуже, чем у алгоритма с расстоянием Дамерау-Левенштейна (что, в общем-то, только подтверждает гипотезу, что необходимо учитывать операцию перестановки). Можно попробовать улучшить алгоритм за счет применения другого способа подсчета расстояния редактирования, например, с помощью меры сходства Джаро-Винклера (алгоритм работает чуть быстрее, чем расстояние Левенштейна и Дамерау-Левенштейна, но в нашем случае, скорее всего, значительного ускорения не даст, т.к. мы и уже ускорили алгоритм за счет get_closest_match_vec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8a24489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.jaro_winkler):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "    closest_reverse = defaultdict(list)\n",
    "    for candidate in closest:\n",
    "        closest_reverse[candidate[1]].append(candidate[0])\n",
    "    closest_reverse = {key: max([i for i in value], key=P) for key, value in closest_reverse.items()}\n",
    "    closest = Counter({value: key for key, value in closest_reverse.items()})\n",
    "    return closest.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b41b991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0.8502251125562781\n",
      "0.44642857142857145\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ba6a0",
   "metadata": {},
   "source": [
    "Метрики оказались похуже, значит, в качестве базовой метрики редактирования оставляем расстояние Дамерау-Левенштейна."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dc23db",
   "metadata": {},
   "source": [
    "3) В первом задании параметр topn для расчета расстояния редактирования был равен 3, а для косинусного расстояния 3*4=12. Попробуем увеличить topn, исходя из предположения, что некоторые хорошие кандидаты на этапе нахождения близких слов по косинусному расстоянию удаляются и не доходят до get_closest_match_with_metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b9aae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(text, X, vec, topn=10, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "    closest_reverse = defaultdict(list)\n",
    "    for candidate in closest:\n",
    "        closest_reverse[candidate[1]].append(candidate[0])\n",
    "    closest_reverse = {key: max([i for i in value], key=P) for key, value in closest_reverse.items()}\n",
    "    closest = Counter({value: key for key, value in closest_reverse.items()})\n",
    "    return closest.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a18a522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0.8574287143571786\n",
      "0.5023291925465838\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f08f28",
   "metadata": {},
   "source": [
    "4) Метрики улучшились. Попробуем увеличить topn для косинусного расстояния. Увеличивать topn для расстояния редактирования, кажется, смысла нет, так как вряд ли среди кандидатов будет очень много тех, у которых одинаковое расстояние редактирования (по алгоритму мы выбираем кандидата с наибольшей метрикой расстояния редактирования, и вероятностный подход применяется только если таких кандидатов несколько)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc621873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(text, X, vec, topn=10, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*6)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "    closest_reverse = defaultdict(list)\n",
    "    for candidate in closest:\n",
    "        closest_reverse[candidate[1]].append(candidate[0])\n",
    "    closest_reverse = {key: max([i for i in value], key=P) for key, value in closest_reverse.items()}\n",
    "    closest = Counter({value: key for key, value in closest_reverse.items()})\n",
    "    return closest.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dbc16e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0.8584292146073037\n",
      "0.5100931677018633\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec60a41",
   "metadata": {},
   "source": [
    "5) Так как метрики улучшились, попробуем все-таки увеличить topn еще в 2 раза (пусть и для расстояния редактирования, и для косинусного расстояния количество кандидатов увеличится)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13ad1e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(text, X, vec, topn=20, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*6)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "    closest_reverse = defaultdict(list)\n",
    "    for candidate in closest:\n",
    "        closest_reverse[candidate[1]].append(candidate[0])\n",
    "    closest_reverse = {key: max([i for i in value], key=P) for key, value in closest_reverse.items()}\n",
    "    closest = Counter({value: key for key, value in closest_reverse.items()})\n",
    "    return closest.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02d9235b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0.8581290645322661\n",
      "0.5077639751552795\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad66594",
   "metadata": {},
   "source": [
    "6) Кажется, улучшения предыдущий эксперимент не дал (значит, увеличение количества кандидатов на этапе подсчета расстояния редактирования действительно не имеет значения). Тогда попробуем оставить topn=10, а topn для косинусного расстояния еще увеличим (до 80)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acb536b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(text, X, vec, topn=10, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*8)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "    closest_reverse = defaultdict(list)\n",
    "    for candidate in closest:\n",
    "        closest_reverse[candidate[1]].append(candidate[0])\n",
    "    closest_reverse = {key: max([i for i in value], key=P) for key, value in closest_reverse.items()}\n",
    "    closest = Counter({value: key for key, value in closest_reverse.items()})\n",
    "    return closest.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "720a3aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0.8583291645822911\n",
      "0.5093167701863354\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa0b29",
   "metadata": {},
   "source": [
    "Улучшения по метрикам мы не видим, значит, дальнейшее увеличение кандидатов на этапе подсчета косинусного расстояния смысла не имеет. Остановимся на параметрах topn=10 для расстояния редактирования и topn*6 для косинусного расстояния."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75342d14",
   "metadata": {},
   "source": [
    "7) Попробуем теперь посмотреть на параметры векторайзера. Возможно, имеет смысл увеличить max_features, так как сейчас словарь н-грамм состоит только из 1000 признаков (только для 33 букв русского алфавита (а символов в словаре наверняка больше) общий объем сочетаний 1, 2 и 3 символов составляет 33 + 33^2 + 33^3 = 37059, в нашем словаре правильных слов должно быть почти столько же). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a93455e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1,3), max_features=5000)\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15963e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(text, X, vec, topn=10, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*6)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "    closest_reverse = defaultdict(list)\n",
    "    for candidate in closest:\n",
    "        closest_reverse[candidate[1]].append(candidate[0])\n",
    "    closest_reverse = {key: max([i for i in value], key=P) for key, value in closest_reverse.items()}\n",
    "    closest = Counter({value: key for key, value in closest_reverse.items()})\n",
    "    return closest.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19f00400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0.8577288644322161\n",
      "0.5046583850931677\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5145a55b",
   "metadata": {},
   "source": [
    "8) Метрики не улучшились. Попробуем увеличить max_features еще в 2 раза."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fce64c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1,3), max_features=10000)\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7be373d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0.8577288644322161\n",
      "0.5046583850931677\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4019cf",
   "metadata": {},
   "source": [
    "9) Метрики остались такие же, значит, взяли слишком большое увеличение параметра, которое никак не отразилось на работе алгоритма. Попробуем остановиться на 2000 признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9339bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1,3), max_features=2000)\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d22e59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0.8577288644322161\n",
      "0.5046583850931677\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b89e88",
   "metadata": {},
   "source": [
    "10) Улучшений по метрикам нет, поэтому теперь попробуем, наоборот, уменьшить количество признаков, например, до 800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76506320",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1,3), max_features=800)\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42052b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0.8584292146073037\n",
      "0.5100931677018633\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2dc526",
   "metadata": {},
   "source": [
    "Теперь результаты не отличаются от тех, которые давал алгоритм с векторайзером, где max_feautures=1000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d9662f",
   "metadata": {},
   "source": [
    "По результатам экспериментов оптимальными параметрами для алгоритма будут: metric=textdistance.damerau_levenshtein, topn=10 (для get_closest_match_with_metric), topn*6 (для get_closest_match_vec) и max_features=1000 (для векторайзера)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
